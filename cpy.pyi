# =======================================================
# ğŸ± BNU æ™ºèƒ½é£Ÿå ‚åŠ©æ‰‹ï¼ˆè¯­éŸ³è¾“å…¥ + è‡ªå­¦ä¹  + åé¦ˆå¯è§†åŒ–ç‰ˆï¼‰
# =======================================================
import os
import pandas as pd
import jieba
import joblib
import streamlit as st
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from lightgbm import LGBMClassifier
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import speech_recognition as sr  # ğŸ™ï¸ è¯­éŸ³è¾“å…¥æ”¯æŒ

# ------------------- è·¯å¾„è®¾ç½® -------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MENU_FILE = os.path.join(BASE_DIR, "menu_data.csv")
FEEDBACK_FILE = os.path.join(BASE_DIR, "user_feedback.csv")
MODEL_FILE = os.path.join(BASE_DIR, "user_model.pkl")

# ------------------- åŠ è½½èœå• -------------------
def load_menu():
    try:
        df = pd.read_csv(MENU_FILE, encoding="utf-8-sig")
    except UnicodeDecodeError:
        df = pd.read_csv(MENU_FILE, encoding="gbk")

    df["tags"] = df["tags"].apply(lambda x: x.split(";") if isinstance(x, str) else [])
    df["price"] = pd.to_numeric(df["price"], errors="coerce").fillna(0)
    df["calories"] = pd.to_numeric(df["calories"], errors="coerce").fillna(0)
    return df

# ------------------- ç‰¹å¾æ„é€  -------------------
def prepare_features(df, text):
    corpus = [" ".join([row["name"]] + row["tags"]) for _, row in df.iterrows()]
    user_cut = " ".join(jieba.lcut(text))
    vectorizer = TfidfVectorizer()
    tfidf = vectorizer.fit_transform(corpus + [user_cut])
    sim = cosine_similarity(tfidf[-1], tfidf[:-1]).flatten()

    df["similarity"] = sim
    scaler = MinMaxScaler()
    df["price_norm"] = scaler.fit_transform(df[["price"]])
    df["cal_norm"] = scaler.fit_transform(df[["calories"]])
    return df, df[["similarity", "price_norm", "cal_norm"]]

# ------------------- ä¿å­˜åé¦ˆ -------------------
def save_feedback(dish_name, liked):
    try:
        if not os.path.exists(FEEDBACK_FILE):
            pd.DataFrame(columns=["dish", "liked", "time"]).to_csv(FEEDBACK_FILE, index=False, encoding="utf-8-sig")

        new = pd.DataFrame([[dish_name, int(liked), datetime.now().strftime("%Y-%m-%d %H:%M:%S")]],
                           columns=["dish", "liked", "time"])
        new.to_csv(FEEDBACK_FILE, mode="a", index=False, header=False, encoding="utf-8-sig")

        if liked:
            st.success(f"ğŸ‘ å·²è®°å½•åé¦ˆï¼šä½ å–œæ¬¢ã€{dish_name}ã€")
        else:
            st.warning(f"ğŸ‘ å·²è®°å½•åé¦ˆï¼šä½ ä¸å–œæ¬¢ã€{dish_name}ã€")

    except Exception as e:
        st.error(f"ä¿å­˜åé¦ˆå¤±è´¥ï¼š{e}")

# ------------------- æ¨¡å‹è®­ç»ƒ -------------------
def retrain_model(df):
    if not os.path.exists(FEEDBACK_FILE):
        st.warning("æš‚æ— ç”¨æˆ·åé¦ˆï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹ã€‚")
        return None

    fb = pd.read_csv(FEEDBACK_FILE)
    if fb.empty:
        st.warning("åé¦ˆæ•°æ®ä¸ºç©ºï¼Œè¯·å¤šç‚¹å‡ æ¬¡å–œæ¬¢/ä¸å–œæ¬¢ã€‚")
        return None

    df, _ = prepare_features(df, "è¾£")
    merged = df.merge(fb, left_on="name", right_on="dish", how="inner")

    if merged.empty:
        st.warning("åé¦ˆèœå“ä¸èœå•ä¸åŒ¹é…ï¼Œè¯·æ£€æŸ¥èœåæ˜¯å¦ä¸€è‡´ã€‚")
        return None

    X = merged[["similarity", "price_norm", "cal_norm"]]
    y = merged["liked"]

    if len(y.unique()) < 2:
        st.warning("åé¦ˆæ ·æœ¬ç±»åˆ«è¿‡å°‘ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹ã€‚")
        return None

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = LGBMClassifier(n_estimators=100, learning_rate=0.1)
    model.fit(X_train, y_train)
    joblib.dump(model, MODEL_FILE)

    acc = model.score(X_test, y_test)
    st.success("âœ… æ¨¡å‹å·²æˆåŠŸè®­ç»ƒå¹¶ä¿å­˜ï¼")
    st.info(f"æ¨¡å‹åœ¨æµ‹è¯•é›†å‡†ç¡®ç‡ï¼š{acc:.2%}")

    st.session_state.model = model
    return model

# ------------------- åŠ è½½æ¨¡å‹ -------------------
def load_or_init_model():
    if os.path.exists(MODEL_FILE):
        try:
            model = joblib.load(MODEL_FILE)
            _ = model.predict([[0, 0, 0]])
            return model
        except Exception:
            return None
    return None

# ------------------- æ¨èç®—æ³• -------------------
def smart_recommend(df, text, model=None, canteen=None):
    df, X = prepare_features(df, text)
    if model is not None:
        try:
            df["predict"] = model.predict_proba(X)[:, 1]
            df["score"] = 0.6 * df["predict"] + 0.4 * df["similarity"]
        except Exception:
            df["score"] = df["similarity"]
    else:
        df["score"] = 0.7 * df["similarity"] + 0.3 * (1 - df["price_norm"])

    if canteen and canteen != "æ‰€æœ‰é£Ÿå ‚":
        df = df[df["canteen"] == canteen]

    return df.sort_values("score", ascending=False).head(5)

# ------------------- ğŸ™ï¸ è¯­éŸ³è¯†åˆ«åŠŸèƒ½ -------------------
def record_and_recognize():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("ğŸ¤ è¯·å¼€å§‹è¯´è¯ï¼ˆæœ€å¤š5ç§’ï¼‰...")
        audio = r.listen(source, phrase_time_limit=5)
        st.info("ğŸ•“ è¯†åˆ«ä¸­ï¼Œè¯·ç¨å€™...")
        try:
            text = r.recognize_google(audio, language="zh-CN")
            st.success(f"âœ… è¯†åˆ«ç»“æœï¼š{text}")
            return text
        except sr.UnknownValueError:
            st.warning("âŒ æ²¡å¬æ¸…ï¼Œè¯·å†è¯•ä¸€æ¬¡ã€‚")
        except sr.RequestError:
            st.error("âš ï¸ ç½‘ç»œé—®é¢˜ï¼Œæ— æ³•è¿æ¥åˆ°è¯­éŸ³è¯†åˆ«æœåŠ¡ã€‚")
    return ""

# ------------------- Streamlit ç•Œé¢ -------------------
st.set_page_config(page_title="BNU æ™ºèƒ½é£Ÿå ‚åŠ©æ‰‹", page_icon="ğŸ±", layout="centered")
st.title("ğŸ± åŒ—äº¬å¸ˆèŒƒå¤§å­¦ Â· æ™ºèƒ½é£Ÿå ‚åŠ©æ‰‹ï¼ˆè¯­éŸ³è¾“å…¥ä¿®æ­£ç‰ˆï¼‰")
st.caption("ğŸ’¬ è¯´å‡ºæˆ–è¾“å…¥ä½ çš„å£å‘³ï¼Œè®©ç³»ç»Ÿæ¨èæœ€é€‚åˆä½ çš„èœï¼")

# è¾“å…¥åŒºåŸŸ
col1, col2 = st.columns([3, 1])
with col1:
    text = st.text_input("è¯·è¾“å…¥éœ€æ±‚ï¼š", placeholder="ä¾‹å¦‚ï¼šæ¸…æ·¡ä½è„‚ æˆ– æƒ³åƒè¾£çš„")
with col2:
    if st.button("ğŸ¤ è¯­éŸ³è¾“å…¥"):
        spoken = record_and_recognize()
        if spoken:
            text = spoken

canteen = st.selectbox("é€‰æ‹©é£Ÿå ‚ï¼š", ["æ‰€æœ‰é£Ÿå ‚", "å­¦ä¸€é£Ÿå ‚", "å­¦äºŒé£Ÿå ‚", "å­¦ä¸‰é£Ÿå ‚", "å­¦å››é£Ÿå ‚"])

menu_data = load_menu()
model = st.session_state.get("model", load_or_init_model())

# æ¨èæŒ‰é’®
if st.button("ğŸ½ï¸ å¼€å§‹æ¨è"):
    if not text.strip():
        st.warning("è¯·è¾“å…¥æˆ–è¯­éŸ³è¾“å…¥ä½ çš„éœ€æ±‚å†è¯•ï¼")
    else:
        recs = smart_recommend(menu_data, text, model, canteen)
        if recs.empty:
            st.info("æš‚æ— ç¬¦åˆæ¡ä»¶çš„èœã€‚")
        else:
            st.subheader("ğŸœ æ¨èèœå“")
            for i, (_, row) in enumerate(recs.iterrows()):
                with st.expander(f"{row['name']} | {row['canteen']}"):
                    st.write(f"ğŸ’° ä»·æ ¼ï¼šÂ¥{row['price']}")
                    st.write(f"ğŸ”¥ çƒ­é‡ï¼š{row['calories']} kcal")
                    st.write(f"ğŸ·ï¸ æ ‡ç­¾ï¼š{'ã€'.join(row['tags'])}")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.button("ğŸ‘ å–œæ¬¢", key=f"like_{i}_{row['name']}",
                                  on_click=lambda d=row["name"]: save_feedback(d, 1))
                    with col2:
                        st.button("ğŸ‘ ä¸å–œæ¬¢", key=f"dislike_{i}_{row['name']}",
                                  on_click=lambda d=row["name"]: save_feedback(d, 0))

# é‡æ–°è®­ç»ƒæ¨¡å‹
if st.button("ğŸ§  é‡æ–°è®­ç»ƒæ¨¡å‹"):
    retrain_model(menu_data)

# ------------------- ğŸ“Š å¯è§†åŒ–åé¦ˆ -------------------
st.divider()
st.header("ğŸ“Š ç”¨æˆ·åé¦ˆåˆ†æ")

if os.path.exists(FEEDBACK_FILE):
    fb = pd.read_csv(FEEDBACK_FILE)
    if not fb.empty:
        tab1, tab2, tab3 = st.tabs(["ğŸ¥§ å–œå¥½æ¯”ä¾‹", "ğŸ± çƒ­é—¨èœå“", "ğŸ•’ è¶‹åŠ¿åˆ†æ"])

        # å–œå¥½æ¯”ä¾‹
        with tab1:
            liked_counts = fb["liked"].value_counts().rename({1: "å–œæ¬¢", 0: "ä¸å–œæ¬¢"})
            fig1, ax1 = plt.subplots()
            ax1.pie(liked_counts, labels=liked_counts.index, autopct="%1.1f%%", startangle=90)
            ax1.axis("equal")
            st.pyplot(fig1)
            st.info(f"æ€»åé¦ˆæ•°ï¼š{len(fb)} æ¡")

        # çƒ­é—¨èœå“ TOP5
        with tab2:
            top_liked = fb[fb["liked"] == 1]["dish"].value_counts().head(5)
            if not top_liked.empty:
                fig2, ax2 = plt.subplots()
                ax2.barh(top_liked.index, top_liked.values)
                ax2.set_xlabel("å–œæ¬¢æ¬¡æ•°")
                ax2.set_title("ğŸ² ç”¨æˆ·æœ€å–œæ¬¢çš„èœå“ TOP5")
                st.pyplot(fig2)
            else:
                st.info("æš‚æ— å–œæ¬¢åé¦ˆæ•°æ®ã€‚")

        # è¶‹åŠ¿åˆ†æ
        with tab3:
            if "time" in fb.columns:
                fb["date"] = pd.to_datetime(fb["time"]).dt.date
                trend = fb.groupby(["date", "liked"]).size().unstack(fill_value=0)
                fig3, ax3 = plt.subplots()
                trend.plot(ax=ax3, marker="o")
                ax3.set_title("ğŸ“… æ¯æ—¥åé¦ˆè¶‹åŠ¿")
                ax3.set_xlabel("æ—¥æœŸ")
                ax3.set_ylabel("åé¦ˆæ•°é‡")
                st.pyplot(fig3)
            else:
                st.info("åé¦ˆæ•°æ®ç¼ºå°‘æ—¶é—´æˆ³ã€‚")
    else:
        st.info("æš‚æ— åé¦ˆè®°å½•ï¼Œè¯·è¿›è¡Œèœå“åé¦ˆåæŸ¥çœ‹ç»“æœã€‚")
else:
    st.info("æš‚æ— åé¦ˆæ–‡ä»¶ï¼Œè¯·å…ˆæäº¤ä¸€æ¬¡åé¦ˆã€‚")

st.caption("ğŸ“˜ æœ¬ç³»ç»ŸåŸºäº TF-IDF + LightGBM + è¯­éŸ³è¯†åˆ« å®ç°æ™ºèƒ½è‡ªå­¦ä¹ æ¨èã€‚")
