import os
import jieba
import joblib
import numpy as np
import pandas as pd
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from lightgbm import LGBMClassifier

# ===========================
# ğŸŒŸ Streamlit é¡µé¢è®¾ç½®
# ===========================
st.set_page_config(page_title="AI æ™ºèƒ½é£Ÿå ‚åŠ©æ‰‹", page_icon="ğŸ±", layout="wide")

# ===========================
# ğŸ“‚ è·¯å¾„å®šä¹‰
# ===========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MENU_FILE = os.path.join(BASE_DIR, "menu_data.csv")
FEEDBACK_FILE = os.path.join(BASE_DIR, "user_feedback.csv")
MODEL_FILE = os.path.join(BASE_DIR, "user_model.pkl")

# ===========================
# ğŸ“Š åŠ è½½èœå•æ•°æ®ï¼ˆå¸¦ BOM/åˆ—æ£€æŸ¥ï¼‰
# ===========================
@st.cache_data
def load_menu():
    if not os.path.exists(MENU_FILE):
        st.error("âŒ æœªæ‰¾åˆ° menu_data.csvï¼Œè¯·ç¡®ä¿å®ƒä¸ app.py åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
        st.stop()

    # å°è¯•ä¸åŒç¼–ç è¯»å– CSVï¼ˆæ”¯æŒ Excel å¯¼å‡ºçš„ UTF-8-BOMï¼‰
    try:
        df = pd.read_csv(MENU_FILE, encoding="utf-8-sig")
    except Exception:
        try:
            df = pd.read_csv(MENU_FILE, encoding="utf-8")
        except Exception:
            df = pd.read_csv(MENU_FILE, encoding="gbk")

    # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
    required_cols = ["name", "canteen", "price", "calories"]
    for col in required_cols:
        if col not in df.columns:
            st.error(f"âŒ menu_data.csv ç¼ºå°‘å¿…è¦åˆ—ï¼š'{col}'ã€‚è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
            st.stop()

    # å¤„ç† tags åˆ—
    if "tags" not in df.columns:
        df["tags"] = ""
    df["tags"] = df["tags"].apply(lambda x: x.split(";") if isinstance(x, str) else [])

    # è½¬æ¢æ•°å€¼åˆ—
    df["price"] = pd.to_numeric(df["price"], errors="coerce").fillna(0)
    df["calories"] = pd.to_numeric(df["calories"], errors="coerce").fillna(0)
    return df

menu_data = load_menu()

# ===========================
# ğŸ§  æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—
# ===========================
def compute_similarity(df, text):
    corpus = [" ".join([str(row["name"])] + row["tags"]) for _, row in df.iterrows()]
    user_cut = " ".join(jieba.lcut(text))
    vectorizer = TfidfVectorizer()
    tfidf = vectorizer.fit_transform(corpus + [user_cut])
    sim = cosine_similarity(tfidf[-1], tfidf[:-1]).flatten()
    df["similarity"] = sim
    return df

# ===========================
# ğŸ”§ ç‰¹å¾å·¥ç¨‹
# ===========================
def prepare_features(df, text):
    df = compute_similarity(df, text)
    df["price_norm"] = MinMaxScaler().fit_transform(df[["price"]])
    df["cal_norm"] = MinMaxScaler().fit_transform(df[["calories"]])
    return df, df[["similarity", "price_norm", "cal_norm"]].values

# ===========================
# ğŸ’¾ æ¨¡å‹åŠ è½½ / åˆå§‹åŒ–
# ===========================
def load_or_init_model():
    if os.path.exists(MODEL_FILE):
        return joblib.load(MODEL_FILE)
    return LGBMClassifier(n_estimators=80, learning_rate=0.1, random_state=42)

model = load_or_init_model()

# ===========================
# ğŸ“ åé¦ˆä¿å­˜
# ===========================
def record_feedback(dish_name, liked):
    new_row = pd.DataFrame([[dish_name, int(liked)]], columns=["dish", "liked"])
    if os.path.exists(FEEDBACK_FILE):
        df = pd.read_csv(FEEDBACK_FILE)
        df = pd.concat([df, new_row], ignore_index=True)
    else:
        df = new_row
    df.to_csv(FEEDBACK_FILE, index=False, encoding="utf-8")

# ===========================
# ğŸ§© æ¨¡å‹é‡æ–°è®­ç»ƒ
# ===========================
def retrain_model(df):
    if not os.path.exists(FEEDBACK_FILE):
        st.warning("æš‚æ— ç”¨æˆ·åé¦ˆï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹ã€‚")
        return None
    fb = pd.read_csv(FEEDBACK_FILE)
    merged = df.merge(fb, left_on="name", right_on="dish", how="inner")
    if merged.empty:
        st.warning("åé¦ˆæ•°æ®ä¸ºç©ºï¼Œæ¨¡å‹æœªæ›´æ–°ã€‚")
        return None

    X = merged[["similarity", "price_norm", "cal_norm"]]
    y = merged["liked"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    new_model = LGBMClassifier(n_estimators=100, learning_rate=0.1)
    new_model.fit(X_train, y_train)
    joblib.dump(new_model, MODEL_FILE)
    st.success("âœ… æ¨¡å‹å·²é‡æ–°è®­ç»ƒæˆåŠŸï¼")
    return new_model

# ===========================
# ğŸ½ï¸ æ¨èé€»è¾‘
# ===========================
from sklearn.exceptions import NotFittedError

def smart_recommend(df, text, model=None, canteen=None):
    # ç‰¹å¾è®¡ç®—
    df, X = prepare_features(df, text)

    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
    model_ready = False
    if model is not None:
        try:
            _ = model.predict_proba([[0, 0, 0]])  # å°è¯•è™šæ‹Ÿé¢„æµ‹
            model_ready = True
        except NotFittedError:
            st.warning("âš ï¸ æ¨¡å‹å°šæœªè®­ç»ƒï¼Œä½¿ç”¨åŸºç¡€ç›¸ä¼¼åº¦æ¨èã€‚")
        except Exception:
            model_ready = False

    # ä½¿ç”¨æ¨¡å‹é¢„æµ‹ï¼ˆå¦‚æœæ¨¡å‹å¯ç”¨ï¼‰
    if model_ready:
        try:
            df["predict"] = model.predict_proba(X)[:, 1]
            df["score"] = 0.6 * df["predict"] + 0.4 * df["similarity"]
        except Exception as e:
            st.warning(f"âš ï¸ æ¨¡å‹é¢„æµ‹å¤±è´¥ï¼š{e}")
            df["score"] = 0.7 * df["similarity"] + 0.3 * (1 - df["price_norm"])
    else:
        # æ— æ¨¡å‹æ—¶ä½¿ç”¨ç›¸ä¼¼åº¦+ä»·æ ¼ç»¼åˆæ¨è
        df["score"] = 0.7 * df["similarity"] + 0.3 * (1 - df["price_norm"])

    # æŒ‰é£Ÿå ‚è¿‡æ»¤
    if canteen and canteen != "æ‰€æœ‰é£Ÿå ‚":
        df = df[df["canteen"] == canteen]

    return df.sort_values(by="score", ascending=False).head(5)

# ===========================
# ğŸŒŸ é¡µé¢ä¸»ä½“
# ===========================
st.title("ğŸ± åŒ—äº¬å¸ˆèŒƒå¤§å­¦ Â· AI æ™ºèƒ½é£Ÿå ‚åŠ©æ‰‹ï¼ˆè‡ªå­¦ä¹ ç‰ˆï¼‰")
st.markdown("> ğŸ’¬ ç¤ºä¾‹ï¼š`æ¸…æ·¡ä½è„‚`ã€`æƒ³åƒè¾£çš„`ã€`é«˜è›‹ç™½`")

canteen = st.selectbox("é€‰æ‹©é£Ÿå ‚ï¼š", ["æ‰€æœ‰é£Ÿå ‚"] + sorted(menu_data["canteen"].unique().tolist()))
text = st.text_input("è¯·è¾“å…¥ä½ çš„éœ€æ±‚ï¼š", placeholder="ä¾‹å¦‚ï¼šæ¸…æ·¡ä½è„‚ã€15å…ƒä»¥å†…ã€å¢è‚Œé¤...")

col1, col2 = st.columns([1, 1])
with col1:
    run_btn = st.button("ğŸ½ï¸ æ™ºèƒ½æ¨è")
with col2:
    retrain_btn = st.button("ğŸ§  é‡æ–°è®­ç»ƒæ¨¡å‹")

# ===========================
# ğŸ” æ¨èå±•ç¤º
# ===========================
if run_btn:
    if not text.strip():
        st.warning("è¯·è¾“å…¥é¥®é£Ÿåå¥½ï½")
        st.stop()
    recs = smart_recommend(menu_data, text, model, canteen)
    if recs.empty:
        st.warning("ğŸ˜… å½“å‰æ²¡æœ‰åŒ¹é…çš„èœå“ã€‚")
    else:
        st.subheader("âœ… æ™ºèƒ½æ¨èç»“æœ")
        for _, row in recs.iterrows():
            with st.expander(f"ğŸ› {row['name']}ï¼ˆ{row['price']} å…ƒï¼‰", expanded=True):
                st.markdown(f"""
                - ğŸ”¥ çƒ­é‡ï¼š**{row['calories']} kcal**
                - ğŸ·ï¸ æ ‡ç­¾ï¼š{', '.join(row['tags']) if row['tags'] else 'æš‚æ— æ ‡ç­¾'}
                - ğŸ« é£Ÿå ‚ï¼š{row['canteen']}
                - ğŸ¤– æ¨èå¾—åˆ†ï¼š{row['score']:.3f}
                """)
                c1, c2 = st.columns([1, 1])
                with c1:
                    if st.button(f"ğŸ‘ å–œæ¬¢ {row['name']}", key=f"like_{row['name']}"):
                        record_feedback(row['name'], True)
                        st.success(f"å·²è®°å½•å–œæ¬¢ {row['name']}")
                with c2:
                    if st.button(f"ğŸ‘ ä¸å–œæ¬¢ {row['name']}", key=f"dislike_{row['name']}"):
                        record_feedback(row['name'], False)
                        st.info(f"å·²è®°å½•ä¸å–œæ¬¢ {row['name']}")

# ===========================
# ğŸ” é‡æ–°è®­ç»ƒæŒ‰é’®
# ===========================
if retrain_btn:
    model = retrain_model(menu_data)

# ===========================
# ğŸ“˜ ç®—æ³•è¯´æ˜
# ===========================
st.markdown("---")
st.markdown("""
### ğŸ§  ç®—æ³•åŸç†è¯´æ˜
- **TF-IDF + ä½™å¼¦ç›¸ä¼¼åº¦**ï¼šç†è§£ç”¨æˆ·è¾“å…¥è¯­ä¹‰ï¼›
- **LightGBM æ¨¡å‹**ï¼šæ ¹æ®ç”¨æˆ·åé¦ˆå­¦ä¹ å£å‘³ï¼›
- **å¤šç›®æ ‡æ’åº**ï¼šå¹³è¡¡â€œç›¸ä¼¼åº¦ + ä»·æ ¼ + çƒ­é‡â€ï¼›
- **è‡ªå­¦ä¹ æœºåˆ¶**ï¼šä½ åé¦ˆå¾—è¶Šå¤šï¼Œæ¨èè¶Šç²¾å‡†ã€‚
""")
